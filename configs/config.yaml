path: '/home/temp/MyDir/Projects/aspdfpwjfpwejfwpefwef/Drons/HighRPD_parsed'
batch_size: 24
seed: 42

model:
  name:  mobilnet
  variant: v3_large
  pretrained: true

name: ${model.name}

finetune:
  strategy: lora
  lora:
    r: 4
    alpha: 8
    dropout: 0.2
    target_modules:
      - 'classifier*'
      - 'features.*'
    trainable_modules:
      - 'classifier*'

# Example progressive fine-tuning configuration:
# progressive:
#   schedule:
#     - epoch: 0
#       modules: ['classifier*']
#     - epoch: 5
#       modules: ['features.6*']

dataset:
  data_dir: 'tmp'

trainer:
  max_epochs: 100
  lr: 1e-3
  device: 'cuda'

optimizer: adam

hyperparameter_search:
  optuna:
    direction: maximize
    metric: val_acc
    n_trials: 20
    timeout: null

quantization:
  enabled: false
  mode: qat            # qat or ptq
  backend: fbgemm
  example_input_shape: [1, 3, 224, 224]
  prepare_on_init: true
  convert_on_fit_end: true

onnx_export:
  enabled: false
  checkpoint: null
  input_shape: [1, 3, 224, 224]
  opset_version: 17
  dynamic_batch: true
  device: cpu
  output_path: model.onnx
  input_names: ["input"]
  output_names: ["logits"]
  quantize:
    enabled: false
    mode: dynamic
    weight_type: qint8
    per_channel: false
    output_path: null
