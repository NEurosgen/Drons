path: '/home/temp/MyDir/Projects/Drons/HighRPD_parsed'
batch_size: 96
seed: 42

model:
  name: efficientnet
  variant: b0
  pretrained: true

name: ${model.name}

finetune:
  strategy: lora
  lora:
    r: 8
    alpha: 16
    dropout: 0.1
    target_modules:
      - 'classifier*'
      - 'features.*'
    trainable_modules:
      - 'classifier*'

# Example progressive fine-tuning configuration:
# progressive:
#   schedule:
#     - epoch: 0
#       modules: ['classifier*']
#     - epoch: 5
#       modules: ['features.6*']

dataset:
  data_dir: 'tmp'

trainer:
  max_epochs: 100
  lr: 3e-3
  device: 'cuda'

optimizer: adam

hyperparameter_search:
  optuna:
    direction: maximize
    metric: val_acc
    n_trials: 20
    timeout: null

onnx_export:
  enabled: false
  checkpoint: null
  output_path: "model.onnx"
  input_shape: [1, 3, 224, 224]
  opset_version: 17
  dynamic_batch: true
  device: "cpu"
  input_names: ["input"]
  output_names: ["logits"]
  quantize:
    enabled: false
    mode: dynamic
    weight_type: qint8
    per_channel: false
    output_path: null

